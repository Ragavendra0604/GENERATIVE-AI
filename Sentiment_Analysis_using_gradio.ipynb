{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO54+DFqpfAXul2YOr0isQE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":802},"id":"Ox2xCxQK4CfP","executionInfo":{"status":"ok","timestamp":1744913399862,"user_tz":-330,"elapsed":74524,"user":{"displayName":"ragava","userId":"07864413981108892283"}},"outputId":"d626040f-eebf-4007-9407-64e7c8268afa"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]},{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n","* Running on public URL: https://e79e344203229b7a22.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://e79e344203229b7a22.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Keyboard interruption in main thread... closing server.\n","Killing tunnel 127.0.0.1:7860 <> https://e79e344203229b7a22.gradio.live\n"]},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":10}],"source":["#!pip install -q gradio langchain sentence-transformers faiss-cpu transformers\n","\n","import gradio as gr\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain_community.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.schema import Document\n","from transformers import pipeline\n","\n","corpus = [\n","    \"I love this product! It has changed my life.\",\n","    \"The service was terrible. I am very disappointed.\",\n","    \"Amazing experience, will definitely come back again!\",\n","    \"Not worth the money. The quality was poor.\",\n","    \"I'm neutral about the update. It didnâ€™t do much.\"\n","]\n","\n","def setup_vector_store(corpus):\n","    docs = [Document(page_content=t) for t in corpus]\n","    splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n","    split_docs = splitter.split_documents(docs)\n","    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","    vectorstore = FAISS.from_documents(split_docs, embeddings)\n","    return vectorstore.as_retriever(search_kwargs={\"k\": 2})\n","\n","retriever = setup_vector_store(corpus)\n","classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n","\n","def sentiment_rag_interface(query):\n","    results = retriever.get_relevant_documents(query)\n","    response = \"\"\n","    for i, doc in enumerate(results):\n","        sentiment = classifier(doc.page_content)[0]\n","        response += f\"Match {i+1}:\\n{doc.page_content}\\nâ†’ Sentiment: {sentiment['label']} (Confidence: {sentiment['score']:.2f})\\n\\n\"\n","    return response.strip()\n","\n","with gr.Blocks(title=\"ğŸ’¬ Sentiment RAG Analyzer\") as demo:\n","    gr.Markdown(\"## Ask questions to analyze sentiment from corpus using RAG + Transformers\")\n","    with gr.Row():\n","        query_input = gr.Textbox(label=\"Your Question\", placeholder=\"e.g. What do users feel about quality?\")\n","    output_box = gr.Textbox(label=\"RAG Sentiment Output\", lines=8)\n","    btn = gr.Button(\"Analyze\")\n","\n","    btn.click(sentiment_rag_interface, inputs=query_input, outputs=output_box)\n","\n","demo.launch(debug=True)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"YSk9SRTR6gxO"},"execution_count":null,"outputs":[]}]}